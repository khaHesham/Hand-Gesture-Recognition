{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial code for our Hand Gesture Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML models imports\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "\n",
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "# destribution models imports\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Data manipulation imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "import joblib\n",
    "\n",
    "# visualisation models imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# image processing imports\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "\n",
    "# dealing with files\n",
    "import os\n",
    "\n",
    "# visual dataset (to test randomized gridsearch not needed for now)\n",
    "from sklearn.datasets import make_hastie_10_2  # to test our models\n",
    "\n",
    "# from utils import prepareData, LoadData, FeatureExtraction, preprocess\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(image):\n",
    "    blured_image = cv2.GaussianBlur(image, (7, 7), 0)\n",
    "    \n",
    "    # Extract the Cr channel\n",
    "    ycbcr_image = cv2.cvtColor(blured_image, cv2.COLOR_BGR2YCrCb)\n",
    "    cr_channel = ycbcr_image[:,:,1]\n",
    "\n",
    "    # Apply thresholding to obtain a binary image\n",
    "    _, binary_img = cv2.threshold(cr_channel,0,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Define the structuring element for the closing operation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10))\n",
    "    # Perform the closing operation\n",
    "    closed_img = cv2.dilate(binary_img, kernel, iterations=1)\n",
    "\n",
    "    # Find the contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(closed_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    segmented_image = closed_img.copy()\n",
    "    cv2.drawContours(segmented_image, contours, -1, 255, -1)\n",
    "    \n",
    "    # preprocessed = cv2.bitwise_and(image, image, mask=segmented_image)\n",
    "    # preprocessed = cv2.cvtColor(preprocessed, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return segmented_image, contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def count_peaks(image, contours):\n",
    "    M = cv2.moments(image)\n",
    "    \n",
    "    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    centroid = np.array([cX, cY])\n",
    "\n",
    "    # Find the contour with the maximum area\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    max_contour = np.squeeze(max_contour)\n",
    "    # Find peaks in the x-coordinate of contour points\n",
    "    x = max_contour[:, 0]\n",
    "    \n",
    "    m, n = image.shape\n",
    "    if(centroid[0] < n/2): # the hand is pointing to right\n",
    "        peak_indices, _ = find_peaks(x, distance=200)\n",
    "    else:  # the hand is pointing to left\n",
    "        peak_indices, _ = find_peaks(-x, distance=200)\n",
    "    \n",
    "    peaks = max_contour[peak_indices]\n",
    "    \n",
    "    if len(peak_indices) == 0: return 0\n",
    "\n",
    "    distance = np.linalg.norm(peaks - centroid, axis=1)\n",
    "    max_peak_distance = np.max(distance)\n",
    "\n",
    "    significant_peaks = peaks[distance >= 0.75*max_peak_distance]\n",
    "\n",
    "    # Draw circles around peak points on the original image\n",
    "    # for peak in peaks:\n",
    "    #     cv2.circle(image, peak, 50, (0, 255, 0), -1)\n",
    "    \n",
    "    return(len(significant_peaks))\n",
    "\n",
    "def ratio(contours):\n",
    "    # Find the contour with the maximum area\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    max_contour = np.squeeze(max_contour)\n",
    "\n",
    "    area = cv2.contourArea(max_contour)\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "    area_bounding_rectangle = w*h\n",
    "    ratio = area/area_bounding_rectangle\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureExtraction(image):\n",
    "        \n",
    "    # Extract the hog features\n",
    "    # block_norm uses L2 norm with hysterisis for reducing effect of illuminacity\n",
    "    # transform_sqrt for applying gamma correction\n",
    "    preprocessed_image, contours = segment(image)\n",
    "    \n",
    "    resized_image = resize(preprocessed_image,(64,128))\n",
    "\n",
    "    # hog_features = hog(resized_image, block_norm='L2-Hys', feature_vector=True, transform_sqrt=True, pixels_per_cell=(12, 12), cells_per_block=(2, 2))\n",
    "    contour_to_ROI = ratio(contours)\n",
    "    peak_num = count_peaks(preprocessed_image, contours)\n",
    "    \n",
    "    # features = np.append(hog_features, (contour_to_ROI, peak_num))\n",
    "    features = np.array([contour_to_ROI, peak_num])\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOurModel(path):\n",
    "    '''\n",
    "       this is a utility function used to load the test data\n",
    "    '''\n",
    "\n",
    "    Features = []\n",
    "    datadir = path\n",
    "    # loop over gender\n",
    "    counter=1\n",
    "    for img in sorted(os.listdir(datadir)):\n",
    "        # ignoring anything except images\n",
    "        if((img.split('.')[-1]).lower() not in ['jpg', 'png', 'jpeg']):\n",
    "            continue\n",
    "        if counter>54:\n",
    "            ourPath= datadir + \"/\" + '(' + str(counter)+\").jpeg\"\n",
    "        else:\n",
    "            ourPath= datadir + \"/\" + '(' + str(counter)+\").jpg\"   \n",
    "        print(ourPath)\n",
    "        # loading our images\n",
    "        img_array = io.imread(ourPath)\n",
    "        counter=counter+1\n",
    "        # append extracted features to Featurees list\n",
    "        Features.append(FeatureExtraction(img_array))\n",
    "\n",
    "    # here i have features need to pass them to my model\n",
    "\n",
    "    svm = joblib.load('kiro_model.pkl')\n",
    "\n",
    "    y_pred = svm.predict(pd.DataFrame(Features))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def readFinalResults(resultFilePath):\n",
    "    ''' \n",
    "        this is a utility function used to read the \n",
    "        file which contains the actual results for \n",
    "        the test data. \n",
    "        input:\n",
    "            resultFilePath: the path of the file which contains the actual results for the test data.\n",
    "        output:\n",
    "            results: the actual results for the test data.\n",
    "    '''\n",
    "    f = open(resultFilePath, 'r')\n",
    "    results = f.read()\n",
    "    f.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData():\n",
    "    Features=[]\n",
    "    labels=[]\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    \n",
    "    for gender in [\"men\",\"Women\"]:\n",
    "        datadir = r\"Dataset\\{}\".format(gender)\n",
    "        # loop over gender\n",
    "        for hand in os.listdir(datadir): \n",
    "            # loop over each class [0,1,2,3,4,5]\n",
    "            for img in os.listdir(datadir+ \"/\" +str(hand)):\n",
    "                # ignoring anything except images\n",
    "                if((img.split('.')[-1]).lower() not in ['jpg','png','jpeg']):\n",
    "                    continue\n",
    "\n",
    "                # loading our images\n",
    "                img_array=io.imread(datadir + \"/\" + str(hand) + \"/\" + img )  # approx 2500 * 4000\n",
    "\n",
    "                # append extracted features to Featurees list   \n",
    "                Feature = FeatureExtraction(img_array)        \n",
    "                Features.append(Feature) \n",
    "\n",
    "                # append class of image.\n",
    "                labels.append(hand)  \n",
    "\n",
    "                print(f'image Number: {i}')\n",
    "                i+=1\n",
    "                # # print(f'saving block : {i//100}')\n",
    "                # # np.save(f'Features/{i}.npy', Feature)\n",
    "                # # Features = []\n",
    "                # # labels = []\n",
    "                # with open(\"Features.csv\", 'a') as csvfile:\n",
    "                #     csvwriter = csv.writer(csvfile)\n",
    "                #     csvwriter.writerow(Feature)\n",
    "\n",
    "    return np.asarray(Features),np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image Number: 0\n",
      "image Number: 1\n",
      "image Number: 2\n",
      "image Number: 3\n",
      "image Number: 4\n",
      "image Number: 5\n",
      "image Number: 6\n",
      "image Number: 7\n",
      "image Number: 8\n",
      "image Number: 9\n",
      "image Number: 10\n",
      "image Number: 11\n",
      "image Number: 12\n",
      "image Number: 13\n",
      "image Number: 14\n",
      "image Number: 15\n",
      "image Number: 16\n",
      "image Number: 17\n",
      "image Number: 18\n",
      "image Number: 19\n",
      "image Number: 20\n",
      "image Number: 21\n",
      "image Number: 22\n",
      "image Number: 23\n",
      "image Number: 24\n",
      "image Number: 25\n",
      "image Number: 26\n",
      "image Number: 27\n",
      "image Number: 28\n",
      "image Number: 29\n",
      "image Number: 30\n",
      "image Number: 31\n",
      "image Number: 32\n",
      "image Number: 33\n",
      "image Number: 34\n",
      "image Number: 35\n",
      "image Number: 36\n",
      "image Number: 37\n",
      "image Number: 38\n",
      "image Number: 39\n",
      "image Number: 40\n",
      "image Number: 41\n",
      "image Number: 42\n",
      "image Number: 43\n",
      "image Number: 44\n",
      "image Number: 45\n",
      "image Number: 46\n",
      "image Number: 47\n",
      "image Number: 48\n",
      "image Number: 49\n",
      "image Number: 50\n",
      "image Number: 51\n",
      "image Number: 52\n",
      "image Number: 53\n",
      "image Number: 54\n",
      "image Number: 55\n",
      "image Number: 56\n",
      "image Number: 57\n",
      "image Number: 58\n"
     ]
    }
   ],
   "source": [
    "Features, labels = LoadData() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testData/(1).jpg\n",
      "testData/(2).jpg\n",
      "testData/(3).jpg\n",
      "testData/(4).jpg\n",
      "testData/(5).jpg\n",
      "testData/(6).jpg\n",
      "testData/(7).jpg\n",
      "testData/(8).jpg\n",
      "testData/(9).jpg\n",
      "testData/(10).jpg\n",
      "testData/(11).jpg\n",
      "testData/(12).jpg\n",
      "testData/(13).jpg\n",
      "testData/(14).jpg\n",
      "testData/(15).jpg\n",
      "testData/(16).jpg\n",
      "testData/(17).jpg\n",
      "testData/(18).jpg\n",
      "testData/(19).jpg\n",
      "testData/(20).jpg\n",
      "testData/(21).jpg\n",
      "testData/(22).jpg\n",
      "testData/(23).jpg\n",
      "testData/(24).jpg\n",
      "testData/(25).jpg\n",
      "testData/(26).jpg\n",
      "testData/(27).jpg\n",
      "testData/(28).jpg\n",
      "testData/(29).jpg\n",
      "testData/(30).jpg\n",
      "testData/(31).jpg\n",
      "testData/(32).jpg\n",
      "testData/(33).jpg\n",
      "testData/(34).jpg\n",
      "testData/(35).jpg\n",
      "testData/(36).jpg\n",
      "testData/(37).jpg\n",
      "testData/(38).jpg\n",
      "testData/(39).jpg\n",
      "testData/(40).jpg\n",
      "testData/(41).jpg\n",
      "testData/(42).jpg\n",
      "testData/(43).jpg\n",
      "testData/(44).jpg\n",
      "testData/(45).jpg\n",
      "testData/(46).jpg\n",
      "testData/(47).jpg\n",
      "testData/(48).jpg\n",
      "testData/(49).jpg\n",
      "testData/(50).jpg\n",
      "testData/(51).jpg\n",
      "testData/(52).jpg\n",
      "testData/(53).jpg\n",
      "testData/(54).jpg\n",
      "testData/(55).jpeg\n",
      "testData/(56).jpeg\n",
      "testData/(57).jpeg\n",
      "testData/(58).jpeg\n",
      "testData/(59).jpeg\n",
      "testData/(60).jpeg\n",
      "testData/(61).jpeg\n",
      "testData/(62).jpeg\n",
      "testData/(63).jpeg\n",
      "testData/(64).jpeg\n",
      "testData/(65).jpeg\n",
      "testData/(66).jpeg\n",
      "testData/(67).jpeg\n",
      "testData/(68).jpeg\n",
      "testData/(69).jpeg\n",
      "testData/(70).jpeg\n",
      "testData/(71).jpeg\n",
      "testData/(72).jpeg\n",
      "testData/(73).jpeg\n",
      "testData/(74).jpeg\n",
      "testData/(75).jpeg\n",
      "testData/(76).jpeg\n",
      "testData/(77).jpeg\n",
      "testData/(78).jpeg\n",
      "testData/(79).jpeg\n",
      "testData/(80).jpeg\n",
      "testData/(81).jpeg\n",
      "testData/(82).jpeg\n",
      "testData/(83).jpeg\n",
      "testData/(84).jpeg\n",
      "testData/(85).jpeg\n",
      "testData/(86).jpeg\n",
      "testData/(87).jpeg\n",
      "testData/(88).jpeg\n",
      "testData/(89).jpeg\n",
      "testData/(90).jpeg\n",
      "testData/(91).jpeg\n",
      "testData/(92).jpeg\n",
      "testData/(93).jpeg\n",
      "testData/(94).jpeg\n",
      "testData/(95).jpeg\n",
      "testData/(96).jpeg\n",
      "testData/(97).jpeg\n",
      "testData/(98).jpeg\n",
      "testData/(99).jpeg\n",
      "testData/(100).jpeg\n",
      "testData/(101).jpeg\n",
      "testData/(102).jpeg\n",
      "testData/(103).jpeg\n",
      "testData/(104).jpeg\n",
      "testData/(105).jpeg\n",
      "testData/(106).jpeg\n",
      "testData/(107).jpeg\n",
      "testData/(108).jpeg\n",
      "testData/(109).jpeg\n",
      "testData/(110).jpeg\n",
      "testData/(111).jpeg\n",
      "testData/(112).jpeg\n",
      "testData/(113).jpeg\n",
      "testData/(114).jpeg\n",
      "testData/(115).jpeg\n"
     ]
    }
   ],
   "source": [
    "labels = readFinalResults('results_set_2.txt')\n",
    "y_pred = testOurModel('testData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6534090909090908\n"
     ]
    }
   ],
   "source": [
    "print(1-(np.sum(labels[54:] != y_pred[54:]))/len(labels[54:]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* # Selecting the best model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Define hyperparameter grids for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': randint(50, 500),\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 5),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'GradientBoostingClassifier': {\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'n_estimators': randint(50, 500),\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 5),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': uniform(0.01, 10),\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'degree': randint(2, 5),\n",
    "        'gamma': ['scale', 'auto'] + list(np.arange(0.1, 1, 0.1))\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': uniform(0.01, 10),\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': randint(50, 500)\n",
    "    },\n",
    "    'DecisionTreeClassifier': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': randint(2, 20),\n",
    "        'min_samples_split': randint(2, 10),\n",
    "        'min_samples_leaf': randint(1, 5),\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'n_neighbors': randint(3, 30),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "        'leaf_size': randint(10, 100)\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'var_smoothing': uniform(1e-09, 1e-07)\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'hidden_layer_sizes': [(50, 50), (100,), (100, 50)],\n",
    "        'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'alpha': uniform(0.0001, 0.01),\n",
    "        'max_iter': randint(100, 1000)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Create a list of models to train (as example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    GaussianNB()\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Loop over the models and fit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dummy data to test the randomizedSearche function\n",
    "x,y = Features,labels\n",
    "df = pd.DataFrame(x)\n",
    "df['Y'] = y\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2) # this function shuffles the data points, and splits the data into\n",
    "                                                  # 80% training set and 20% test set (indicated by test_size=0.2)\n",
    "X_train, Y_train = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "X_test, Y_test = test.iloc[:, :-1], test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1/5: RandomForestClassifier\n",
      "Best score: 0.400\n",
      "Best parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 130}\n",
      "\n",
      "Training Model 2/5: GradientBoostingClassifier\n",
      "Best score: 0.424\n",
      "Best parameters: {'learning_rate': 0.03703344575971452, 'max_depth': 8, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 68}\n",
      "\n",
      "Training Model 3/5: SVC\n",
      "Best score: 0.451\n",
      "Best parameters: {'C': 8.948624388292055, 'degree': 4, 'gamma': 0.30000000000000004, 'kernel': 'poly'}\n",
      "\n",
      "Training Model 4/5: KNeighborsClassifier\n",
      "Best score: 0.360\n",
      "Best parameters: {'algorithm': 'kd_tree', 'leaf_size': 31, 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Training Model 5/5: GaussianNB\n",
      "Best score: 0.384\n",
      "Best parameters: {'var_smoothing': 8.281483955122005e-08}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    print(f'Training Model {i+1}/{len(models)}: {str(model)[:-2]}')\n",
    "    # Define randomized grid search\n",
    "    random_search = RandomizedSearchCV(model, param_distributions[str(model)[:-2]], n_iter=10,cv=5, n_jobs=-1) # n_jobs means number of jobs to run in parallel. None means 1,\n",
    "                                                                                                                # -1 means using all processors 😈.\n",
    "    # Fit the randomized grid search to the data\n",
    "    random_search.fit(X_train, Y_train)\n",
    "    print(f'Best score: {random_search.best_score_:.3f}')\n",
    "    print(f'Best parameters: {random_search.best_params_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
